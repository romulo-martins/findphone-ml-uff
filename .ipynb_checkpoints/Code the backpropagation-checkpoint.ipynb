{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code The Backpropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementação foi baseada no exemplo do notebook backpropagation passo-a-passo, tanto os dados quanto as ideias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def calculate_output(self, inputs):\n",
    "        self.output = self.activation(self.net(inputs))\n",
    "        return self.output\n",
    "        \n",
    "    # Realiza o calculo de soma(W*x + b)    \n",
    "    def net(self, inputs):\n",
    "        return np.dot(self.weights, inputs) + self.bias    \n",
    "    \n",
    "    # Função de ativação, no caso estamos utilizando a função logistica f(x) = 1/(1 + exp(-x)) que gera curva sigmoide\n",
    "    def activation(self, net):\n",
    "        return 1.0 / (1.0 + np.exp(-net))\n",
    "\n",
    "    # Derivada da função logistica, se f'(x) = f(x)(1 - f(x))\n",
    "    def derivative_activation(self):\n",
    "        return self.output*(1 - self.output)\n",
    "    \n",
    "    def calculate_delta(self, target):\n",
    "        self.delta = (self.output - target)*self.derivative_activation() \n",
    "        return self.delta\n",
    "    \n",
    "    def update_weights(self, learning_rate, errors_total_weights):\n",
    "        for i in range(0, len(self.weights)):\n",
    "            self.weights[i] -= learning_rate * errors_total_weights[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    LEARNING_RATE = 0.5\n",
    "    \n",
    "    # Número de entradas de dados, número de nós na camada oculta e número de nós de saida.\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "        # OBS: Dados de teste do artigo que serviu de base\n",
    "        self.hidden_layer = [ Neuron([.15, .20], .35), Neuron([.25, .30], .35) ]\n",
    "        self.output_layer = [ Neuron([.40, .45], .60), Neuron([.50, .55], .60) ]\n",
    "        \n",
    "        # self.hidden_layer = self.init_layer_weights(num_inputs, num_hidden)\n",
    "        # self.output_layer = self.init_layer_weights(num_hidden, num_outputs)\n",
    "        \n",
    "    # Inicia as camadas de neuronios com pesos gerados aleatoriamente para cada neuronio     \n",
    "    def init_layer_weights(self, num_weights, num_neurons):\n",
    "        neurons_layer = []\n",
    "        for i in range(0, num_neurons):\n",
    "            weights = np.random.randn(num_weights) * 0.05 \n",
    "            bias = (np.random.randn(1) * 0.05)[0] \n",
    "            neurons_layer.append(Neuron(weights, bias))\n",
    "        return neurons_layer\n",
    "        \n",
    "    def forward_pass(self, inputs):\n",
    "        outputs_hidden = self.feed_forward(inputs, self.hidden_layer)\n",
    "        return self.feed_forward(outputs_hidden, self.output_layer)\n",
    "    \n",
    "    def backward_pass(self, targets):\n",
    "        \"\"\"\n",
    "            TODO: \n",
    "        \"\"\"\n",
    "\n",
    "    # calculando deltas para a camada de saida (output layer)    \n",
    "    def compute_output_deltas(self, targets):\n",
    "        for neuron, target in zip(self.output_layer, targets):\n",
    "            neuron.calculate_delta(target)\n",
    "        \n",
    "    # Atualização dos pesos, só pode ser executado se o calculo dos deltas for realizado antes    \n",
    "    def update_output_weights(self):\n",
    "        for o_neuron in self.output_layer:\n",
    "            errors_total_weights = []\n",
    "            for h_neuron, o_weights in zip(self.hidden_layer, o_neuron.weights):\n",
    "                errors_total_weights.append(o_neuron.delta * h_neuron.output)\n",
    "            o_neuron.update_weights(self.LEARNING_RATE, errors_total_weights)\n",
    "        \n",
    "    def feed_forward(self, inputs, neurons):\n",
    "        outputs = []\n",
    "        for neuron in neurons:\n",
    "            outputs.append(neuron.calculate_output(inputs))\n",
    "        return outputs\n",
    "    \n",
    "    def calculate_error(self, target, output):\n",
    "        return (0.5)*(target - output)**2\n",
    "    \n",
    "    def calculate_total_error(self, targets, outputs):\n",
    "        total_error = 0.0\n",
    "        for target, output in zip(targets, outputs):\n",
    "            total_error += self.calculate_error(target, output)\n",
    "        return total_error\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar, utilizaremos os seguintes dados do exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2983711087600027"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [.05, .10]\n",
    "targets = [.01, .99]\n",
    "\n",
    "nn = NeuralNetwork(num_inputs=2, num_hidden=2, num_outputs=2)\n",
    "nn_out = nn.forward_pass(inputs)\n",
    "nn.calculate_total_error(nn_out, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Hidden Layer outputs -----\n",
      "0.5932699921071872\n",
      "0.596884378259767\n"
     ]
    }
   ],
   "source": [
    "print(\"----- Hidden Layer outputs -----\")\n",
    "for n in nn.hidden_layer:\n",
    "    print(n.output)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Output Layer outputs -----\n",
      "0.7513650695523157\n",
      "0.7729284653214625\n"
     ]
    }
   ],
   "source": [
    "print(\"----- Output Layer outputs -----\")\n",
    "for n in nn.output_layer:\n",
    "    print(n.output)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apos o backward pass os pesos da Output Layer devem ser alterados para os seguintes valores:\n",
    "[0.35891648, 0.408666186], [ 0.511301270, 0.561370121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Output Layer Weights -----\n",
      "[0.4, 0.45]\n",
      "[0.5, 0.55]\n"
     ]
    }
   ],
   "source": [
    "print(\"----- Output Layer Weights -----\")    \n",
    "for n in nn.output_layer:\n",
    "    print(n.weights)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apos o backward pass os pesos da Hidden Layer devem ser alterados para os seguintes valores:\n",
    "[,], [,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Hidden Layer Weights -----\n",
      "[0.15, 0.2]\n",
      "[0.25, 0.3]\n"
     ]
    }
   ],
   "source": [
    "print(\"----- Hidden Layer Weights -----\")    \n",
    "for n in nn.hidden_layer:\n",
    "    print(n.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 0.45]\n",
      "[0.5, 0.55]\n"
     ]
    }
   ],
   "source": [
    "nn.compute_output_deltas(targets)\n",
    "for n in nn.output_layer:\n",
    "    print(n.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05539942465142279"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eo1 = nn.output_layer[0].delta * nn.output_layer[0].weights[0]\n",
    "eo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.019049118258278114"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eo2 = nn.output_layer[1].delta * nn.output_layer[1].weights[0]\n",
    "eo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03635030639314468"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_total = eo1 + eo2\n",
    "e_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_deltas_weights(index):\n",
    "    total_delta_weight = 0\n",
    "    for neuron in nn.output_layer:\n",
    "        total_delta_weight += neuron.delta * neuron.weights[index]\n",
    "    return total_delta_weight    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1497807161327628\n",
      "0.19956143226552567\n",
      "0.24975114363236958\n",
      "0.29950228726473915\n"
     ]
    }
   ],
   "source": [
    "def update_hidden_weights():\n",
    "    for i, neuron in enumerate(nn.hidden_layer):\n",
    "        for j in range(0, len(neuron.weights)):\n",
    "            total_deltas_weights = compute_total_deltas_weights(i)            \n",
    "            \n",
    "            error_total_weight = total_deltas_weights * neuron.derivative_activation() * inputs[j]\n",
    "            \n",
    "            weight_updated = neuron.weights[j] - 0.5* error_total_weight\n",
    "            \n",
    "            print(weight_updated)\n",
    "\n",
    "update_hidden_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
