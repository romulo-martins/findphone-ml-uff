{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code The Backpropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementação foi baseada no exemplo do notebook backpropagation passo-a-passo, tanto os dados quanto as ideias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.total_weight_errors = []\n",
    "        \n",
    "    def calculate_output(self, inputs):\n",
    "        self.inputs = self.inputs\n",
    "        self.output = self.activation(self.net(inputs))\n",
    "        return self.output\n",
    "        \n",
    "    # Realiza o calculo de soma(W*x + b)    \n",
    "    def net(self, inputs):\n",
    "        total = 0\n",
    "        for i in range(len(inputs)):\n",
    "            total += inputs[i] * self.weights[i]\n",
    "        return total + self.bias\n",
    "#         return np.dot(self.weights, inputs) + self.bias    \n",
    "    \n",
    "    # Função de ativação, no caso estamos utilizando a função logistica f(x) = 1/(1 + exp(-x)) que gera curva sigmoide\n",
    "    def activation(self, net):\n",
    "        return 1.0 / (1.0 + np.exp(-net))\n",
    "\n",
    "    # Derivada da função logistica, se f'(x) = f(x)(1 - f(x))\n",
    "    def derivative_activation(self):\n",
    "        return self.output*(1 - self.output)\n",
    "    \n",
    "    def calculate_delta(self, target):\n",
    "        self.delta = (self.output - target)*self.derivative_activation() \n",
    "        return self.delta\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        for i in range(0, len(self.weights)):\n",
    "            self.weights[i] -= learning_rate * self.total_weight_errors[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    LEARNING_RATE = 0.5\n",
    "    \n",
    "    # Número de entradas de dados, número de nós na camada oculta e número de nós de saida.\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "        # OBS: Dados de teste do artigo que serviu de base\n",
    "#         self.hidden_layer = [ Neuron([.15, .20], .35), Neuron([.25, .30], .35) ]\n",
    "#         self.output_layer = [ Neuron([.40, .45], .60), Neuron([.50, .55], .60) ]\n",
    "        \n",
    "        # As camadas são um conjunto de neuronios\n",
    "        self.hidden_layer = self.init_layer_weights(num_inputs, num_hidden)\n",
    "        self.output_layer = self.init_layer_weights(num_hidden, num_outputs)\n",
    "        \n",
    "    # Inicia as camadas de neuronios com pesos gerados aleatoriamente para cada neuronio     \n",
    "    def init_layer_weights(self, num_weights, num_neurons):\n",
    "        neurons_layer = []\n",
    "        for i in range(0, num_neurons):\n",
    "            weights = np.random.randn(num_weights) * 0.05 \n",
    "            bias = (np.random.randn(1) * 0.05)[0] \n",
    "            neurons_layer.append(Neuron(weights, bias))\n",
    "        return neurons_layer\n",
    "    \n",
    "    \n",
    "    def backpropagation(self, inputs_list, targets):\n",
    "        for inputs in inputs_list:        \n",
    "            prediction = self.forward_pass(inputs)\n",
    "            print(\"Prediction: \", prediction)\n",
    "\n",
    "            error = self.calculate_total_error(targets, prediction)\n",
    "            print(\"\\nError: \", error)\n",
    "\n",
    "            print(\"\\n----- Pesos antes -----\")\n",
    "            self.show_weights()\n",
    "\n",
    "            self.backward_pass(targets)\n",
    "\n",
    "            print(\"\\n----- Pesos depois ----- \")\n",
    "            self.show_weights()\n",
    "        \n",
    "    def forward_pass(self, inputs):\n",
    "        outputs_hidden = self.feed_forward(inputs, self.hidden_layer)\n",
    "        return self.feed_forward(outputs_hidden, self.output_layer)\n",
    "    \n",
    "    def feed_forward(self, inputs, neurons):\n",
    "        outputs = []\n",
    "        for neuron in neurons:\n",
    "            outputs.append(neuron.calculate_output(inputs))\n",
    "        return outputs\n",
    "    \n",
    "    def backward_pass(self, targets):\n",
    "        # Calcula os deltas para todos pesos (weights) da hidden layer para output layer\n",
    "        self.compute_output_deltas(targets)\n",
    "        # Calcula os deltas para todos pesos (weights) da input layer para hidden layer\n",
    "        self.compute_hidden_deltas()\n",
    "        \n",
    "        # Atualização dos pesos, só pode ser executado se o calculo dos deltas for realizado antes\n",
    "        self.update_weights(self.output_layer)\n",
    "        self.update_weights(self.hidden_layer)\n",
    "        \n",
    "    # calculando deltas para a camada de saida (output layer)    \n",
    "    def compute_output_deltas(self, targets):\n",
    "        for neuron, target in zip(self.output_layer, targets):\n",
    "            neuron.calculate_delta(target)\n",
    "        \n",
    "        for o_neuron in self.output_layer:\n",
    "            for h_neuron, o_weights in zip(self.hidden_layer, o_neuron.weights):\n",
    "                total_weight_error = o_neuron.delta * h_neuron.output\n",
    "                o_neuron.total_weight_errors.append(total_weight_error)\n",
    "        \n",
    "    def update_weights(self, layer):\n",
    "        for neuron in layer:\n",
    "            neuron.update_weights(self.LEARNING_RATE)\n",
    "        \n",
    "    def compute_total_deltas_weights(self, index):\n",
    "        total_delta_weight = 0\n",
    "        for neuron in nn.output_layer:\n",
    "            total_delta_weight += neuron.delta * neuron.weights[index]\n",
    "        return total_delta_weight\n",
    "    \n",
    "    def compute_hidden_deltas(self):\n",
    "        for i, neuron in enumerate(self.hidden_layer):\n",
    "            for j in range(0, len(neuron.weights)):\n",
    "                total_deltas_weights = self.compute_total_deltas_weights(i)            \n",
    "                total_weight_error = total_deltas_weights * neuron.derivative_activation() * inputs[j]\n",
    "                neuron.total_weight_errors.append(total_weight_error)\n",
    "    \n",
    "    def calculate_error(self, target, output):\n",
    "        return (0.5)*(target - output)**2\n",
    "    \n",
    "    def calculate_total_error(self, targets, outputs):\n",
    "        total_error = 0.0\n",
    "        for target, output in zip(targets, outputs):\n",
    "            total_error += self.calculate_error(target, output)\n",
    "        return total_error\n",
    "    \n",
    "    def show_weights(self):\n",
    "        print(\"\\nOutput Layer: \")\n",
    "        for neuron in self.output_layer:\n",
    "            print(neuron.weights)\n",
    "        \n",
    "        print(\"\\nHidden Layer: \")\n",
    "        for neuron in self.hidden_layer:\n",
    "            print(neuron.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar, utilizaremos os seguintes dados do exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inputs_list = [[.05, .10]]\n",
    "# targets = [.01, .99]\n",
    "\n",
    "# nn = NeuralNetwork(num_inputs=2, num_hidden=2, num_outputs=2)\n",
    "# nn.backpropagation(inputs_list, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atualização de pesos para Output Layer:\n",
    "[0.358916479, 0.408666186]\n",
    "[0.511301270, 0.561370121]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atualização de pesos para Hidden Layer:\n",
    "[0.149780716, 0.19956143]\n",
    "[0,24975114, 0,29950229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [0.5186212721954605, 0.4815513749620628, 0.5117352498047204]\n",
      "\n",
      "Error:  1.3441238139061744\n",
      "\n",
      "----- Pesos antes -----\n",
      "\n",
      "Output Layer: \n",
      "[-0.03721569  0.06286769]\n",
      "[-0.05086116 -0.11062193]\n",
      "[-0.02603887  0.05838272]\n",
      "\n",
      "Hidden Layer: \n",
      "[-0.07267975 -0.02131278  0.04951894 -0.0255697 ]\n",
      "[0.00470088 0.04009994 0.01332642 0.02349047]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-5578dba3f33b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackpropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-475f9f86877d>\u001b[0m in \u001b[0;36mbackpropagation\u001b[1;34m(self, inputs_list, targets)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n----- Pesos depois ----- \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-475f9f86877d>\u001b[0m in \u001b[0;36mbackward_pass\u001b[1;34m(self, targets)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_output_deltas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# Calcula os deltas para todos pesos (weights) da input layer para hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_hidden_deltas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# Atualização dos pesos, só pode ser executado se o calculo dos deltas for realizado antes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-475f9f86877d>\u001b[0m in \u001b[0;36mcompute_hidden_deltas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mtotal_deltas_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_total_deltas_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mtotal_weight_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_deltas_weights\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mneuron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mderivative_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[0mneuron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_weight_errors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_weight_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# import a dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "\n",
    "nn = NeuralNetwork(num_inputs=4, num_hidden=2, num_outputs=3)\n",
    "nn.backpropagation(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
